복수의 예에 대한 학습처리
학습 대상인 w1, w2, b에 대해 모두 비용계산을 거치고
모두 더한 뒤 예의 갯수인 m으로 나눠서 평균을 구함
이후,  w1, w2, b에 대하여 미분값을 구해 학습 비율인 a와 곱한 값을 빼서 조정을 거침

여기까지가 한단계


연산에 for문을 활용하면 속도가 느리게 될 것임으로,
백터 행렬을 활용해 한번에 처리하게 됨 



n개의 traning데이터를 벡터화 시킨 행렬  = X
열 == 트레이닝 셋 / 행 == 트레이닝에서 각각의 특징


A = [ a1. .... ] / Y=[y1.... ]
dZ = A-Y 가 됨
이러한 dZ의 내부 값을 더하고 m으로 나누면
결과 한번에 처리가됨

전체적 loop는 남아있음




뉴럴 신경망
기존의 특성들이 하나의계산으로 끝나는 것에 비해
복수의 계산을 종합해 결과가 도출되는 일반적인 모델

새로운 기호
[ i ] == i는 단계 계산을 지칭

input layer == 최초 입력값인 x1, x2, x3 ...
hidden layer == 계산이 이뤄지는 복수의 단계
output layer == 복수 단계에 의한 결과를 바탕으로한 최종 값

복수의 계산에 따른 각각의 w와 b 값이 생기게 됨으로 이들을 행렬로 표현함 


hidden 레이어 단계에서는 각각의 input을 받아서, z 식인 = wx + b 를 통해
시그노이드 함수를 적용한 값을 output 함


표현하면
a i ^[n] 은 n계층에서 i 번째 노드의 시그노이드 값이됨


